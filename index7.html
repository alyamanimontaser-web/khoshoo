<!DOCTYPE html>

<html lang="ar">
<head>
<meta charset="UTF-8" />
<title>رصد وضعيات الصلاة – نسخة مستقرة</title>
<style>
  body { font-family: Arial, sans-serif; text-align: center; background: #f5f5f5; margin: 0; }
  h2 { margin-top: 10px; }
  #container { position: relative; width: 640px; margin: auto; }
  video, canvas {
    width: 640px;
    height: 480px;
    position: absolute;
    left: 0;
    top: 0;
    transform: scaleX(-1);
  }
  canvas { pointer-events: none; }
  #controls { margin-top: 500px; }
</style>
</head>
<body>

<h2>تطبيق رصد وضعيات الصلاة</h2>

<div id="container">
  <video id="video" autoplay playsinline></video>
  <canvas id="canvas" width="640" height="480"></canvas>
</div>

<div id="controls">
  <button id="startBtn">ابدأ</button>
  <p id="status">في الانتظار…</p>
</div>

<!-- الأصوات -->

<audio id="qiyam" src="qiyam.mp3"></audio> <audio id="ruku" src="ruku.mp3"></audio> <audio id="sujood" src="sujood.mp3"></audio> <audio id="juloos" src="juloos.mp3"></audio>

<script type="module">
// ===== IMPORTS (مضمونة بدون MediaPipe) =====
import * as tf from "https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.12.0/dist/tf.min.js";
import * as poseDetection from "https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection@2.1.3/dist/pose-detection.esm.js";

const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');
const statusEl = document.getElementById('status');

const sounds = {
  qiyam: document.getElementById('qiyam'),
  ruku: document.getElementById('ruku'),
  sujood: document.getElementById('sujood'),
  juloos: document.getElementById('juloos'),
};

let detector;
let maxHeight = 0;
let lastPose = '';
let lastTime = 0;

// ===== START BUTTON =====
document.getElementById('startBtn').onclick = startApp;

async function startApp() {
  statusEl.textContent = 'تشغيل الكاميرا…';

  const stream = await navigator.mediaDevices.getUserMedia({ video: true });
  video.srcObject = stream;

  detector = await poseDetection.createDetector(
    poseDetection.SupportedModels.BlazePose,
    {
      runtime: 'tfjs',
      modelType: 'lite'
    }
  );

  statusEl.textContent = 'جارٍ الرصد…';
  requestAnimationFrame(loop);
}

// ===== UTILITIES =====
function bodyHeight(kp) {
  const valid = kp.filter(p => p.score > 0.5);
  if (valid.length < 5) return 0;
  const ys = valid.map(p => p.y);
  return Math.max(...ys) - Math.min(...ys);
}

function angle(a, b, c) {
  const ab = { x: a.x - b.x, y: a.y - b.y };
  const cb = { x: c.x - b.x, y: c.y - b.y };
  const dot = ab.x * cb.x + ab.y * cb.y;
  const mag = Math.hypot(ab.x, ab.y) * Math.hypot(cb.x, cb.y);
  return Math.acos(dot / mag) * 180 / Math.PI;
}

function detectPose(kp) {
  const get = n => kp.find(p => p.name === n && p.score > 0.5);
  const hip = get('right_hip');
  const knee = get('right_knee');
  const ankle = get('right_ankle');
  if (!hip || !knee || !ankle) return null;

  const h = bodyHeight(kp);
  if (h > maxHeight) maxHeight = h;
  if (!maxHeight) return null;

  const ratio = h / maxHeight;
  const kneeAngle = angle(hip, knee, ankle);

  if (ratio < 0.45) return 'sujood';
  if (ratio < 0.65 && kneeAngle < 130) return 'juloos';
  if (ratio < 0.85) return 'ruku';
  if (kneeAngle > 160) return 'qiyam';

  return null;
}

function drawSkeleton(kp) {
  ctx.clearRect(0, 0, canvas.width, canvas.height);
  ctx.fillStyle = 'red';
  kp.forEach(p => {
    if (p.score > 0.5) {
      ctx.beginPath();
      ctx.arc(p.x, p.y, 4, 0, Math.PI * 2);
      ctx.fill();
    }
  });
}

// ===== MAIN LOOP =====
async function loop() {
  const poses = await detector.estimatePoses(video);
  if (poses.length) {
    const kp = poses[0].keypoints;
    drawSkeleton(kp);

    const pose = detectPose(kp);
    if (pose && pose !== lastPose && performance.now() - lastTime > 600) {
      sounds[pose]?.play();
      statusEl.textContent = pose;
      lastPose = pose;
      lastTime = performance.now();
    }
  }
  requestAnimationFrame(loop);
}
</script>

</body>
</html>
